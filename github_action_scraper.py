#!/usr/bin/env python3
"""
üÜì GITHUB ACTIONS ƒ∞LE √úCRETSƒ∞Z SCRAPER
Tamamen √ºcretsiz ve kalƒ±cƒ± √ß√∂z√ºm
"""

import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import sqlite3
import pandas as pd
from datetime import datetime
import time
import random
import os

def github_action_scraper():
    """GitHub Actions ortamƒ±nda √ßalƒ±≈üacak scraper"""

    # GitHub Actions i√ßin Chrome ayarlarƒ±
    options = uc.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')

    # Undetected ChromeDriver - Cloudflare bypass
    driver = uc.Chrome(options=options, version_main=120)

    conn = sqlite3.connect('market_spider.db')
    cursor = conn.cursor()

    # Tablo olu≈ütur (yoksa)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS products (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT,
            brand TEXT,
            price REAL,
            rating REAL,
            review_count INTEGER,
            url TEXT UNIQUE,
            site_name TEXT,
            category_id INTEGER,
            in_stock BOOLEAN,
            created_at TIMESTAMP,
            updated_at TIMESTAMP
        )
    """)

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS product_reviews (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            product_id INTEGER,
            reviewer_name TEXT,
            rating REAL,
            review_text TEXT,
            review_date TIMESTAMP,
            helpful_count INTEGER,
            sentiment_score REAL,
            scraped_at TIMESTAMP
        )
    """)

    conn.commit()

    products_data = []

    try:
        print("üåê Trendyol'a baƒülanƒ±lƒ±yor...")
        driver.get("https://www.trendyol.com/cok-satanlar")

        # Cloudflare challenge'ƒ± ge√ßmesi i√ßin bekle
        time.sleep(10)

        # Sayfayƒ± a≈üaƒüƒ± kaydƒ±r (lazy loading i√ßin)
        for i in range(5):
            driver.execute_script(f"window.scrollTo(0, {i * 1000});")
            time.sleep(2)

        # √úr√ºnleri topla
        products = driver.find_elements(By.CSS_SELECTOR, "div.p-card-wrppr")
        print(f"‚úÖ {len(products)} √ºr√ºn bulundu")

        for idx, product in enumerate(products[:50], 1):  # ƒ∞lk 50 √ºr√ºn
            try:
                # JavaScript ile veri √ßek (daha g√ºvenilir)
                product_data = driver.execute_script("""
                    var elem = arguments[0];
                    var link = elem.querySelector('a');
                    var name = elem.querySelector('.prdct-desc-cntnr-name');
                    var brand = elem.querySelector('.prdct-desc-cntnr-ttl');
                    var price = elem.querySelector('.prc-box-dscntd');
                    var rating = elem.querySelector('.rating-score');

                    return {
                        url: link ? link.href : '',
                        name: name ? name.innerText : '',
                        brand: brand ? brand.innerText : '',
                        price: price ? price.innerText : '',
                        rating: rating ? rating.innerText : ''
                    };
                """, product)

                if product_data['name']:
                    # Fiyatƒ± temizle
                    price_str = product_data['price'].replace(' TL', '').replace('.', '').replace(',', '.')
                    try:
                        price = float(price_str)
                    except:
                        price = 0

                    # Veritabanƒ±na ekle
                    cursor.execute("""
                        INSERT OR REPLACE INTO products (
                            name, brand, price, url, site_name,
                            created_at, in_stock, rating
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        product_data['name'],
                        product_data['brand'],
                        price,
                        product_data['url'],
                        'Trendyol',
                        datetime.now(),
                        1,
                        float(product_data['rating']) if product_data['rating'] else 0
                    ))

                    products_data.append(product_data)
                    print(f"  {idx}. ‚úÖ {product_data['name'][:40]}")

                    # Her 10 √ºr√ºnde bir commit
                    if idx % 10 == 0:
                        conn.commit()

            except Exception as e:
                print(f"  {idx}. ‚ùå Hata: {e}")
                continue

        conn.commit()

        # CSV'ye kaydet
        if products_data:
            df = pd.DataFrame(products_data)
            df.to_csv('scraped_products.csv', index=False)
            print(f"\n‚úÖ {len(products_data)} √ºr√ºn CSV'ye kaydedildi")

    except Exception as e:
        print(f"‚ùå Ana hata: {e}")

    finally:
        driver.quit()
        conn.close()

    print("\nüéâ Scraping tamamlandƒ±!")
    return len(products_data)

if __name__ == "__main__":
    # GitHub Actions ortam deƒüi≈ükeni kontrol√º
    if os.environ.get('GITHUB_ACTIONS'):
        print("ü§ñ GitHub Actions ortamƒ±nda √ßalƒ±≈üƒ±yor")

    result = github_action_scraper()
    print(f"\nüìä Toplam {result} √ºr√ºn toplandƒ±")