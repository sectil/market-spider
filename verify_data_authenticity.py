#!/usr/bin/env python3
"""
ğŸ” VERÄ° DOÄRULAMA - SimÃ¼lasyon mu GerÃ§ek mi?
"""

import sqlite3
import pandas as pd
from datetime import datetime

conn = sqlite3.connect('market_spider.db')

print("="*70)
print("ğŸ” VERÄ° KAYNAK ANALÄ°ZÄ°")
print("="*70)

# 1. ÃœrÃ¼nler tablosunu kontrol et
print("\nğŸ“¦ ÃœRÃœNLER ANALÄ°ZÄ°:")
print("-"*50)

products = pd.read_sql_query("""
    SELECT
        site_name,
        COUNT(*) as count,
        MIN(created_at) as first_added,
        MAX(created_at) as last_added
    FROM products
    GROUP BY site_name
""", conn)

for _, row in products.iterrows():
    print(f"  Kaynak: {row['site_name']}")
    print(f"  ÃœrÃ¼n sayÄ±sÄ±: {row['count']}")
    print(f"  Ä°lk ekleme: {row['first_added']}")
    print(f"  Son ekleme: {row['last_added']}")
    print()

# 2. URL'leri kontrol et
print("ğŸ“ Ã–RNEK ÃœRÃœN URL'LERÄ°:")
print("-"*50)
sample_urls = pd.read_sql_query("""
    SELECT name, url FROM products LIMIT 5
""", conn)

for _, row in sample_urls.iterrows():
    print(f"  {row['name'][:30]:32} -> {row['url']}")

# 3. YorumlarÄ± kontrol et
print("\nğŸ’¬ YORUMLAR ANALÄ°ZÄ°:")
print("-"*50)

review_stats = pd.read_sql_query("""
    SELECT
        COUNT(*) as total_reviews,
        COUNT(DISTINCT reviewer_name) as unique_reviewers,
        MIN(review_date) as oldest_review,
        MAX(review_date) as newest_review,
        AVG(LENGTH(review_text)) as avg_review_length
    FROM product_reviews
""", conn).iloc[0]

print(f"  Toplam yorum: {review_stats['total_reviews']}")
print(f"  Benzersiz yorum yazan: {review_stats['unique_reviewers']}")
print(f"  En eski yorum: {review_stats['oldest_review']}")
print(f"  En yeni yorum: {review_stats['newest_review']}")
print(f"  Ortalama yorum uzunluÄŸu: {review_stats['avg_review_length']:.0f} karakter")

# 4. Yorum iÃ§eriklerini analiz et
print("\nğŸ“ YORUM Ä°Ã‡ERÄ°K ANALÄ°ZÄ°:")
print("-"*50)

# Tekrar eden yorumlar var mÄ±?
duplicate_reviews = pd.read_sql_query("""
    SELECT
        review_text,
        COUNT(*) as count
    FROM product_reviews
    WHERE review_text IS NOT NULL
    GROUP BY review_text
    HAVING COUNT(*) > 1
    LIMIT 5
""", conn)

if len(duplicate_reviews) > 0:
    print("  âš ï¸ UYARI: Tekrar eden yorumlar bulundu!")
    for _, row in duplicate_reviews.iterrows():
        print(f"    '{row['review_text'][:50]}...' - {row['count']} kez")
else:
    print("  âœ… Tekrar eden yorum yok")

# 5. Yorum yazan isimleri kontrol et
print("\nğŸ‘¥ EN Ã‡OK YORUM YAZAN KÄ°ÅÄ°LER:")
print("-"*50)

top_reviewers = pd.read_sql_query("""
    SELECT
        reviewer_name,
        COUNT(*) as review_count
    FROM product_reviews
    GROUP BY reviewer_name
    ORDER BY review_count DESC
    LIMIT 10
""", conn)

for _, row in top_reviewers.iterrows():
    print(f"  {row['reviewer_name']:20} - {row['review_count']} yorum")

# 6. GerÃ§ek veri kaynaÄŸÄ±nÄ± kontrol et
print("\nğŸ” VERÄ° KAYNAÄI TESPÄ°TÄ°:")
print("-"*50)

# Scraped_at alanÄ±nÄ± kontrol et
scraped_data = pd.read_sql_query("""
    SELECT COUNT(*) as count
    FROM product_reviews
    WHERE scraped_at IS NOT NULL
""", conn).iloc[0]['count']

print(f"  Web'den Ã§ekilmiÅŸ yorum sayÄ±sÄ±: {scraped_data}")
print(f"  Kod ile oluÅŸturulmuÅŸ yorum sayÄ±sÄ±: {review_stats['total_reviews'] - scraped_data}")

# 7. SONUÃ‡
print("\n" + "="*70)
print("ğŸ“Š SONUÃ‡:")
print("="*70)

if scraped_data > 100:
    print("âœ… VERÄ°LER GERÃ‡EK - Web'den Ã§ekilmiÅŸ")
elif "example.com" in sample_urls['url'].iloc[0]:
    print("âš ï¸ VERÄ°LER SÄ°MÃœLASYON - Ã–rnek URL'ler kullanÄ±lmÄ±ÅŸ")
    print("   Ama kategorilere Ã¶zel, gerÃ§ekÃ§i iÃ§erikler oluÅŸturulmuÅŸ")
else:
    print("ğŸ”„ KARMA VERÄ° - Hem gerÃ§ek hem simÃ¼lasyon")

print(f"""
ğŸ“Œ DURUM RAPORU:
- ÃœrÃ¼nler: Trendyol benzeri gerÃ§ekÃ§i Ã¼rÃ¼nler
- URL'ler: example.com (simÃ¼lasyon)
- Yorumlar: Kategoriye Ã¶zel, TÃ¼rkÃ§e, gerÃ§ekÃ§i
- Yorum yazanlar: {review_stats['unique_reviewers']} farklÄ± TÃ¼rk ismi
- Ä°Ã§erik kalitesi: YÃ¼ksek (ortalama {review_stats['avg_review_length']:.0f} karakter)

NOT: Network kÄ±sÄ±tlamalarÄ± nedeniyle gerÃ§ek Trendyol'dan veri
Ã§ekilemedi. Ancak tÃ¼m veriler gerÃ§ekÃ§i ve analiz iÃ§in uygun.
""")

conn.close()