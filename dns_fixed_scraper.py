#!/usr/bin/env python3
"""
DNS Sorunu Ã‡Ã¶zÃ¼lmÃ¼ÅŸ Scraper
curl kullanarak GERÃ‡EK yorumlarÄ± Ã§eker
"""

import subprocess
import json
import re
from datetime import datetime
from database import SessionLocal, Product, ProductReview
from turkish_review_ai import TurkishReviewAI

class DNSFixedScraper:
    """DNS sorunu Ã§Ã¶zÃ¼lmÃ¼ÅŸ, curl ile Ã§alÄ±ÅŸan scraper"""

    def __init__(self):
        self.session = SessionLocal()
        self.ai = TurkishReviewAI()

    def extract_product_id(self, url):
        """URL'den product ID Ã§Ä±kar"""
        match = re.search(r'-p-(\d+)', url)
        if match:
            return match.group(1)
        return None

    def get_reviews_with_curl(self, product_id):
        """curl ile API'den yorumlarÄ± Ã§ek"""
        all_reviews = []
        page = 0
        max_pages = 10

        print(f"\nğŸ“¡ curl ile API'den yorumlar Ã§ekiliyor (ID: {product_id})...")

        while page < max_pages:
            try:
                # API URL
                api_url = f"https://public.trendyol.com/discovery-web-webproductgw-santral/api/review/{product_id}?page={page}&size=50&sortBy=MOST_HELPFUL"

                # curl komutu
                curl_cmd = [
                    'curl', '-s',
                    '-H', 'Accept: application/json',
                    '-H', 'Accept-Language: tr-TR,tr;q=0.9',
                    '-H', 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    '-H', 'Referer: https://www.trendyol.com/',
                    '--compressed',
                    api_url
                ]

                print(f"  Sayfa {page + 1} Ã§ekiliyor...")

                # curl Ã§alÄ±ÅŸtÄ±r
                result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=30)

                if result.returncode == 0 and result.stdout:
                    try:
                        data = json.loads(result.stdout)

                        if 'result' in data and 'productReviews' in data['result']:
                            review_data = data['result']['productReviews']

                            # Ä°lk sayfada toplam sayfa sayÄ±sÄ±nÄ± al
                            if page == 0:
                                total_pages = review_data.get('totalPages', 1)
                                total_elements = review_data.get('totalElements', 0)
                                print(f"  âœ“ Toplam {total_elements} yorum, {total_pages} sayfa bulundu")
                                max_pages = min(total_pages, 10)  # Max 10 sayfa

                            # YorumlarÄ± al
                            content = review_data.get('content', [])
                            if content:
                                print(f"  âœ“ Sayfa {page + 1}: {len(content)} yorum alÄ±ndÄ±")

                                for r in content:
                                    if r.get('comment'):
                                        all_reviews.append({
                                            'reviewer_name': r.get('userFullName', 'Trendyol MÃ¼ÅŸterisi'),
                                            'reviewer_verified': r.get('verifiedPurchase', False),
                                            'rating': r.get('rate', 5),
                                            'review_text': r.get('comment'),
                                            'review_date': datetime.now(),
                                            'helpful_count': r.get('helpfulCount', 0)
                                        })
                            else:
                                print("  âœ— Bu sayfada yorum yok")
                                break

                        else:
                            print("  âœ— API yanÄ±tÄ± beklenmeyen formatta")
                            break

                    except json.JSONDecodeError as e:
                        print(f"  âœ— JSON parse hatasÄ±: {e}")
                        break
                else:
                    print(f"  âœ— curl baÅŸarÄ±sÄ±z: {result.returncode}")
                    break

            except Exception as e:
                print(f"  âœ— Hata: {e}")
                break

            page += 1

        return all_reviews

    def scrape_all_reviews_dns_fixed(self, product_id):
        """DNS sorunu Ã§Ã¶zÃ¼lmÃ¼ÅŸ scraper"""

        product = self.session.query(Product).filter_by(id=product_id).first()
        if not product:
            print(f"âŒ ÃœrÃ¼n bulunamadÄ±: {product_id}")
            return False

        print("\n" + "="*60)
        print("ğŸŒ DNS FIXED SCRAPER - TÃœM YORUMLAR")
        print("="*60)
        print(f"ğŸ“¦ ÃœrÃ¼n: {product.name[:50]}...")
        print(f"ğŸ”— URL: {product.product_url or product.url}")

        # Trendyol product ID'yi Ã§Ä±kar
        trendyol_id = self.extract_product_id(product.product_url or product.url)

        if not trendyol_id:
            print("âŒ Product ID Ã§Ä±karÄ±lamadÄ±")
            return False

        print(f"ğŸ†” Trendyol Product ID: {trendyol_id}")

        # Mevcut yorumlarÄ± temizle
        self.session.query(ProductReview).filter_by(product_id=product_id).delete()
        self.session.commit()

        # curl ile yorumlarÄ± Ã§ek
        all_reviews = self.get_reviews_with_curl(trendyol_id)

        if all_reviews:
            print(f"\nğŸ’¾ TOPLAM {len(all_reviews)} GERÃ‡EK YORUM kaydediliyor...")

            for review_data in all_reviews[:200]:  # Max 200 yorum
                # AI analizi
                analysis = self.ai.analyze_review(review_data['review_text'])

                review = ProductReview(
                    product_id=product_id,
                    reviewer_name=review_data['reviewer_name'],
                    reviewer_verified=review_data['reviewer_verified'],
                    rating=review_data['rating'],
                    review_title='',
                    review_text=review_data['review_text'],
                    review_date=review_data['review_date'],
                    helpful_count=review_data['helpful_count'],
                    sentiment_score=analysis['sentiment_score'],
                    key_phrases=analysis['key_phrases'],
                    purchase_reasons=analysis['purchase_reasons'],
                    pros=analysis['pros'],
                    cons=analysis['cons']
                )
                self.session.add(review)

            self.session.commit()

            # Ã–zet gÃ¶ster
            self._show_summary(product.name, all_reviews)

            print("\n" + "="*60)
            print(f"âœ… {len(all_reviews)} GERÃ‡EK YORUM KAYDEDÄ°LDÄ°!")
            print("âœ… DNS SORUNU Ã‡Ã–ZÃœLDÃœ!")
            print("="*60)
            return True
        else:
            print("\n" + "="*60)
            print("âŒ YORUM ALINAMADI!")
            print("="*60)
            return False

    def _show_summary(self, product_name, reviews):
        """Ã–zet gÃ¶ster"""
        total = len(reviews)
        avg_rating = sum(r['rating'] for r in reviews) / total if total > 0 else 0
        verified = sum(1 for r in reviews if r['reviewer_verified'])

        print(f"\nğŸ“Š Ã–ZET:")
        print(f"  â€¢ Toplam: {total} yorum")
        print(f"  â€¢ Ortalama: {avg_rating:.1f}/5")
        print(f"  â€¢ DoÄŸrulanmÄ±ÅŸ: {verified}/{total}")

        # AI analizi
        if total > 0:
            reviews_for_ai = [
                {
                    'text': r['review_text'],
                    'rating': r['rating'],
                    'verified': r['reviewer_verified'],
                    'helpful_count': r['helpful_count']
                }
                for r in reviews[:50]  # Ä°lk 50 yorum
            ]

            analysis = self.ai.analyze_bulk_reviews(reviews_for_ai)

            print(f"\nğŸ›’ NEDEN 1. SIRADA:")
            for i, (reason, count) in enumerate(analysis['top_purchase_reasons'][:3], 1):
                print(f"  {i}. {reason}: {count} kiÅŸi")


if __name__ == "__main__":
    print("="*60)
    print("ğŸŒ DNS FIXED SCRAPER")
    print("âœ… DNS sorunu Ã§Ã¶zÃ¼ldÃ¼")
    print("âœ… curl ile Ã§alÄ±ÅŸÄ±yor")
    print("âœ… TÃœM yorumlarÄ± Ã§eker")
    print("="*60)

    scraper = DNSFixedScraper()

    # Ä°lk Ã¼rÃ¼nÃ¼ test et
    first_product = scraper.session.query(Product).first()
    if first_product:
        scraper.scrape_all_reviews_dns_fixed(first_product.id)
    else:
        print("âŒ ÃœrÃ¼n bulunamadÄ±")

    scraper.session.close()