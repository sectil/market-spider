#!/usr/bin/env python3
"""
Web scraper'Ä± Ã§alÄ±ÅŸtÄ±r ve Ã¼rÃ¼nleri veritabanÄ±na kaydet
"""

import time
from database import SessionLocal, SiteConfig, SiteUrl, Product
from trendyol_scraper import TrendyolScraper
from hepsiburada_scraper import HepsiburadaScraper
from datetime import datetime

def run_scraper(site_key: str = None, max_pages: int = 1):
    """Belirtilen site iÃ§in scraper'Ä± Ã§alÄ±ÅŸtÄ±r"""

    session = SessionLocal()

    try:
        # Site seÃ§
        if site_key:
            sites = session.query(SiteConfig).filter_by(site_key=site_key, is_active=True).all()
        else:
            sites = session.query(SiteConfig).filter_by(is_active=True).all()

        if not sites:
            print("âŒ Aktif site bulunamadÄ±!")
            return

        total_products = 0

        for site in sites:
            print(f"\n{'='*60}")
            print(f"ğŸŒ {site.site_name} scraping baÅŸlÄ±yor...")

            # Site'ye gÃ¶re scraper seÃ§
            if site.site_key == 'trendyol':
                scraper = TrendyolScraper()
            elif site.site_key == 'hepsiburada':
                scraper = HepsiburadaScraper()
            else:
                print(f"âš ï¸ {site.site_key} iÃ§in scraper bulunamadÄ±, geÃ§iliyor...")
                continue

            # Bu site iÃ§in URL'leri al
            urls = session.query(SiteUrl).filter_by(
                site_id=site.id,
                is_active=True
            ).all()

            if not urls:
                print(f"  âš ï¸ {site.site_name} iÃ§in aktif URL bulunamadÄ±")
                continue

            site_product_count = 0

            for url in urls[:3]:  # Ä°lk 3 URL'yi Ã§ek
                print(f"\n  ğŸ“ Kategori: {url.category or 'Genel'}")
                print(f"  ğŸ”— URL: {url.url_path[:80]}...")

                try:
                    # ÃœrÃ¼nleri Ã§ek
                    products = scraper.scrape_products(
                        url=url.url_path,
                        max_pages=max_pages
                    )

                    if products:
                        print(f"  âœ… {len(products)} Ã¼rÃ¼n bulundu")

                        # VeritabanÄ±na kaydet
                        for product_data in products[:50]:  # Ä°lk 50 Ã¼rÃ¼nÃ¼ kaydet
                            # Var olan Ã¼rÃ¼nÃ¼ kontrol et
                            existing = session.query(Product).filter_by(
                                site_id=site.id,
                                site_product_id=product_data.get('id', '')
                            ).first()

                            if not existing:
                                product = Product(
                                    site_id=site.id,
                                    site_product_id=product_data.get('id', ''),
                                    product_id=f"{site.site_key}_{product_data.get('id', '')}",  # Eski uyumluluk iÃ§in
                                    name=product_data.get('name', '')[:500],
                                    price=float(product_data.get('price', 0)),
                                    product_url=product_data.get('url', ''),
                                    url=product_data.get('url', ''),  # Eski uyumluluk iÃ§in
                                    image_url=product_data.get('image', ''),
                                    brand=product_data.get('brand', ''),
                                    category=url.category,
                                    site_name=site.site_key,  # Site adÄ± ekle
                                    seller=product_data.get('seller', ''),
                                    rating=product_data.get('rating'),
                                    review_count=product_data.get('review_count', 0),
                                    in_stock=True,
                                    scraped_at=datetime.now()
                                )
                                session.add(product)
                                site_product_count += 1

                        session.commit()

                        # Ä°lk 3 Ã¼rÃ¼nÃ¼ gÃ¶ster
                        for i, p in enumerate(products[:3], 1):
                            print(f"    {i}. {p.get('name', '')[:50]}... - {p.get('price', 0)} TL")
                    else:
                        print(f"  âš ï¸ ÃœrÃ¼n bulunamadÄ±")

                except Exception as e:
                    print(f"  âŒ Hata: {str(e)}")
                    session.rollback()

                time.sleep(2)  # Rate limiting

            print(f"\nâœ… {site.site_name} iÃ§in {site_product_count} yeni Ã¼rÃ¼n eklendi")
            total_products += site_product_count

        print(f"\n{'='*60}")
        print(f"ğŸ‰ TOPLAM {total_products} yeni Ã¼rÃ¼n veritabanÄ±na eklendi!")

        # Toplam Ã¼rÃ¼n sayÄ±sÄ±nÄ± gÃ¶ster
        total_in_db = session.query(Product).count()
        print(f"ğŸ“¦ VeritabanÄ±nda toplam {total_in_db} Ã¼rÃ¼n var")

    except Exception as e:
        print(f"âŒ Genel hata: {e}")
        session.rollback()
    finally:
        session.close()


if __name__ == "__main__":
    import sys

    # Komut satÄ±rÄ± parametreleri
    site_key = sys.argv[1] if len(sys.argv) > 1 else None
    max_pages = int(sys.argv[2]) if len(sys.argv) > 2 else 1

    print("ğŸš€ Market Spider Scraper")
    print("-" * 60)

    if site_key:
        print(f"Site: {site_key}")
    else:
        print("TÃ¼m aktif siteler Ã§ekilecek")
    print(f"Max sayfa: {max_pages}")

    run_scraper(site_key, max_pages)